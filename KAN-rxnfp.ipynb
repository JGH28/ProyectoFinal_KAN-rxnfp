{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1c86527",
   "metadata": {},
   "source": [
    "# Proyecto Final\n",
    "## KAN para Clasificación de Reacciones Químicas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61819144",
   "metadata": {},
   "source": [
    "### Configuración del Entorno\n",
    "\n",
    "Se importan las librerías necesarias:\n",
    "- `kan` para implementar Kolmogorov-Arnold Networks.\n",
    "- `torch` para trabajar con tensores y GPU.\n",
    "- `numpy` y `pandas` para análisis de datos.\n",
    "\n",
    "Se configura el dispositivo (`cuda` o `cpu`) y se establece la precisión de los tensores en `float64` para cálculos más precisos. Finalmente, se verifica el dispositivo activo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ce52aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from kan import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38755bb",
   "metadata": {},
   "source": [
    "### Carga y preprocesamiento del dataset\n",
    "\n",
    "1. **Carga del Dataset:**\n",
    "   - Se carga el archivo `schneider50k.tsv` usando `pandas`, separando las columnas por tabulaciones (`sep='\\t'`).\n",
    "\n",
    "2. **Cálculo de Superclase:**\n",
    "   - Se agrega una columna llamada `superclass` que contiene el primer dígito de la columna `rxn_class`, ajustado para que las clases comiencen desde `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fcad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/home/jesus_gh/MetodosBiomAI/KAN-RXNFP/schneider50k.tsv',sep='\\t')\n",
    "dataset['superclass'] = dataset['rxn_class'].apply(lambda x: int(str(x).split('.')[0]) - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed459d5",
   "metadata": {},
   "source": [
    "3. **Eliminación de Columnas Innecesarias:**\n",
    "   - Se eliminan las columnas `source` y `split` para limpiar el dataset.\n",
    "\n",
    "4. **Visualización:**\n",
    "   - Se muestran las primeras filas del dataset modificado para verificar los cambios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57c4b6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>original_rxn</th>\n",
       "      <th>rxn_class</th>\n",
       "      <th>rxn</th>\n",
       "      <th>superclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[CH3:17][S:14](=[O:15])(=[O:16])[N:11]1[CH2:10...</td>\n",
       "      <td>6.1.5</td>\n",
       "      <td>C1CCCCC1.CCO.CS(=O)(=O)N1CCN(Cc2ccccc2)CC1.[OH...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>O.O.[Na+].[CH3:1][c:2]1[cH:7][c:6]([N+:8](=O)[...</td>\n",
       "      <td>7.1.1</td>\n",
       "      <td>CCOC(C)=O.Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccccc...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[CH3:1][O:2][c:3]1[cH:4][cH:5][c:6](-[c:9]2[cH...</td>\n",
       "      <td>1.8.5</td>\n",
       "      <td>COc1ccc(-c2coc3ccc(-c4nnc(S)o4)cc23)cc1.COc1cc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Cl.[CH3:43][CH2:42][S:44](=[O:45])(=[O:46])Cl....</td>\n",
       "      <td>2.2.3</td>\n",
       "      <td>CCS(=O)(=O)Cl.CN(C(=O)N(C)[C@@H]1CN(C(=O)C2CCN...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[CH3:25][O:24][c:21]1[cH:22][cH:23][c:17]([O:1...</td>\n",
       "      <td>1.3.7</td>\n",
       "      <td>COc1ccc(OC)c(N)c1.Cc1cc(Cl)nc(-c2ccccn2)n1&gt;&gt;CO...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                       original_rxn rxn_class  \\\n",
       "0           0  [CH3:17][S:14](=[O:15])(=[O:16])[N:11]1[CH2:10...     6.1.5   \n",
       "1           1  O.O.[Na+].[CH3:1][c:2]1[cH:7][c:6]([N+:8](=O)[...     7.1.1   \n",
       "2           2  [CH3:1][O:2][c:3]1[cH:4][cH:5][c:6](-[c:9]2[cH...     1.8.5   \n",
       "3           3  Cl.[CH3:43][CH2:42][S:44](=[O:45])(=[O:46])Cl....     2.2.3   \n",
       "4           4  [CH3:25][O:24][c:21]1[cH:22][cH:23][c:17]([O:1...     1.3.7   \n",
       "\n",
       "                                                 rxn  superclass  \n",
       "0  C1CCCCC1.CCO.CS(=O)(=O)N1CCN(Cc2ccccc2)CC1.[OH...           5  \n",
       "1  CCOC(C)=O.Cc1cc([N+](=O)[O-])ccc1NC(=O)c1ccccc...           6  \n",
       "2  COc1ccc(-c2coc3ccc(-c4nnc(S)o4)cc23)cc1.COc1cc...           0  \n",
       "3  CCS(=O)(=O)Cl.CN(C(=O)N(C)[C@@H]1CN(C(=O)C2CCN...           1  \n",
       "4  COc1ccc(OC)c(N)c1.Cc1cc(Cl)nc(-c2ccccn2)n1>>CO...           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lista de columnas a eliminar\n",
    "columnas_a_eliminar = ['source', 'split',]  \n",
    "\n",
    "# Eliminar las columnas del dataset original\n",
    "dataset.drop(columns=columnas_a_eliminar, inplace=True)\n",
    "\n",
    "# Mostrar las primeras filas del dataset modificado\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb79b5f",
   "metadata": {},
   "source": [
    "### Reducción del Dataset\n",
    "\n",
    "Se toma una muestra aleatoria de 150 filas del dataset original usando `dataset.sample(150)`.\n",
    "\n",
    "- **Motivo:** Debido al tamaño del dataset completo (50,000 filas) y las limitaciones computacionales del entorno, trabajar con un subconjunto más pequeño ayuda a evitar problemas como el colapso del kernel y reduce el tiempo de procesamiento durante el entrenamiento del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6106b5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.sample(150)  # Usar un subconjunto pequeño para probar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c649b23",
   "metadata": {},
   "source": [
    "### Definición de Entradas y Salidas\n",
    "\n",
    "- **Entradas (`inputs`)**: Se seleccionan las cadenas SMILES de las reacciones químicas en la columna `rxn`.\n",
    "- **Salidas (`outputs`)**: Se asignan las etiquetas de las superclases desde la columna `superclass`.\n",
    "\n",
    "Esto define las características (`inputs`) y las etiquetas de clasificación (`outputs`) para el modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94bf5caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = dataset['rxn'] #Indico cuales son las entradas\n",
    "outputs  = dataset['superclass'] #Indico cuales son las salidas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e94791",
   "metadata": {},
   "source": [
    "### Embedding y Padding de las SMILES\n",
    "\n",
    "En esta celda, se transforman las cadenas SMILES en un formato numérico adecuado para el modelo mediante **embedding** y **padding**.\n",
    "\n",
    "#### **1. Embedding (Codificación One-Hot)**\n",
    "- **¿Qué hace?**:\n",
    "  Convierte cada carácter de las SMILES en un vector de una matriz **one-hot**, donde cada fila corresponde a un carácter único.\n",
    "- **Proceso**:\n",
    "  - **Vocabulario (`smiles_vocab`)**: Lista de caracteres únicos encontrados en las SMILES.\n",
    "  - **Función `one_hot_encode_smiles`**:\n",
    "    - Parámetros:\n",
    "      - `smiles`: Cadena SMILES que será codificada.\n",
    "      - `vocab`: Vocabulario de caracteres únicos.\n",
    "      - `max_len`: Longitud máxima permitida para las cadenas.\n",
    "    - Se inicializa una matriz de ceros con tamaño `[max_len, vocab_size]`.\n",
    "    - Cada carácter se asigna a su índice correspondiente en el vocabulario (`char_to_idx`) y se marca con un `1` en la matriz.\n",
    "\n",
    "#### **2. Padding**\n",
    "- **¿Qué hace?**:\n",
    "  Asegura que todas las SMILES tengan la misma longitud (`max_length`), añadiendo ceros para las cadenas más cortas o truncando las más largas.\n",
    "- **Motivo**:\n",
    "  Los modelos KAN requieren entradas con dimensiones uniformes, lo que evita errores durante el procesamiento.\n",
    "\n",
    "#### **3. Implementación con Pandas y PyTorch**\n",
    "- **Librerías utilizadas**:\n",
    "  - `pandas`: Para manipular las columnas del dataset y aplicar la codificación a cada SMILES con `.apply()`.\n",
    "  - `numpy`: Para inicializar y manejar las matrices one-hot.\n",
    "  - `torch`: Para convertir las listas codificadas en tensores adecuados para el modelo (`torch.tensor`).\n",
    "- **Finalización**:\n",
    "  - Las SMILES codificadas y rellenadas se almacenan en `inputs_tokenized`.\n",
    "  - Se convierten a tensores con `dtype=torch.float64` para mantener precisión y compatibilidad con el modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afc82c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_446637/3186771519.py:21: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  inputs_tensor = torch.tensor(inputs_tokenized, dtype=torch.float64, device=device)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Crear una lista de caracteres únicos encontrados en SMILES\n",
    "smiles_vocab = list(set(\"\".join(dataset['rxn'])))\n",
    "max_length = dataset['rxn'].str.len().max()  # Longitud máxima de SMILES\n",
    "\n",
    "# Tokenización con padding\n",
    "def one_hot_encode_smiles(smiles, vocab, max_len):\n",
    "    vocab_size = len(vocab)\n",
    "    char_to_idx = {char: idx for idx, char in enumerate(vocab)}\n",
    "    encoding = np.zeros((max_len, vocab_size))  # Matriz con padding\n",
    "    for i, char in enumerate(smiles[:max_len]):  # Truncar si es necesario\n",
    "        encoding[i, char_to_idx[char]] = 1\n",
    "    return encoding.flatten()\n",
    "\n",
    "# Aplicar la codificación one-hot con padding a todas las entradas SMILES\n",
    "inputs_tokenized = dataset['rxn'].apply(lambda x: one_hot_encode_smiles(x, smiles_vocab, max_length)).tolist()\n",
    "\n",
    "# Convertir las listas tokenizadas en tensores\n",
    "inputs_tensor = torch.tensor(inputs_tokenized, dtype=torch.float64, device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47b2ec6",
   "metadata": {},
   "source": [
    "### División del Dataset en Conjuntos de Entrenamiento y Prueba\n",
    "\n",
    "En esta celda, se separan las entradas y salidas en conjuntos de entrenamiento y prueba.\n",
    "\n",
    "#### **1. Conversión de Salidas a Tensores:**\n",
    "- **Propósito:** Las KANs requieren que las etiquetas (`outputs`) estén en formato tensorial para ser procesadas.\n",
    "- **Implementación:**\n",
    "  - Se utiliza `torch.tensor` para convertir las etiquetas `outputs` en tensores de tipo `float64` y compatibilidad con el dispositivo (`device`).\n",
    "\n",
    "#### **2. División del Dataset:**\n",
    "- **Librería:** `train_test_split` de `scikit-learn`.\n",
    "- **Propósito:** Divide los datos en dos partes:\n",
    "  - `train_inputs` y `train_outputs` (70%): Para entrenar el modelo.\n",
    "  - `test_inputs` y `test_outputs` (30%): Para evaluar el modelo.\n",
    "- **Parámetros Importantes:**\n",
    "  - `test_size=0.3`: El 30% de los datos se asigna al conjunto de prueba.\n",
    "  - `random_state=42`: Semilla para asegurar reproducibilidad.\n",
    "\n",
    "#### **3. Verificación de Dimensiones:**\n",
    "- **Por qué es importante:** Permite confirmar que los tamaños de las particiones son correctos y consistentes con el formato esperado por el modelo.\n",
    "- **Resultado:** Se imprimen las dimensiones de los conjuntos de entrenamiento y prueba.\n",
    "\n",
    "Esto garantiza que los datos estén listos para ser utilizados por el modelo con una separación clara entre entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27d4bda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: torch.Size([105, 13120]), torch.Size([105])\n",
      "Test set: torch.Size([45, 13120]), torch.Size([45])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "# Convertir etiquetas de superclases en tensores\n",
    "outputs_tensor = torch.tensor(outputs.values, dtype=torch.float64, device=device)\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "train_inputs, test_inputs, train_outputs, test_outputs = train_test_split(inputs_tensor, outputs_tensor, test_size=0.3, random_state=42)\n",
    "\n",
    "# Imprimo las dimensiones de los conjuntos de entrenamiento y prueba\n",
    "print(f'Train set: {train_inputs.shape}, {train_outputs.shape}') \n",
    "print(f'Test set: {test_inputs.shape}, {test_outputs.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1466d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train input dtype: torch.float64\n",
      "Test input dtype: torch.float64\n"
     ]
    }
   ],
   "source": [
    "# Imprimir los tipos de datos de los tensores\n",
    "print(f\"Train input dtype: {train_inputs.dtype}\")\n",
    "print(f\"Test input dtype: {test_inputs.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1440c016",
   "metadata": {},
   "source": [
    "### Creación del Diccionario de Dataset\n",
    "\n",
    "Se crea un diccionario llamado `dataset_kan` que contiene los conjuntos de datos de entrada y salida para entrenamiento y prueba. Este formato facilita el acceso y manejo de los datos en el modelo KAN, agrupando las entradas y salidas de manera estructurada.\n",
    "\n",
    "Este paso es crucial para organizar los datos de forma eficiente antes de ser utilizados por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a49a2f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hago un diccionario con los conjuntos de datos\n",
    "dataset_kan = {\n",
    "    'train_input': train_inputs,\n",
    "    'train_label': train_outputs,\n",
    "    'test_input': test_inputs,\n",
    "    'test_label': test_outputs,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63839d10",
   "metadata": {},
   "source": [
    "### Declaración del Modelo KAN\n",
    "\n",
    "En esta celda, se declara el modelo **KAN** con la siguiente estructura:\n",
    "`\"model = KAN(width=[train_inputs.shape[1], [5, 2], 1], grid=3, k=3)`\n",
    "\n",
    "#### Explicación del Modelo:\n",
    "\n",
    "*width=[train_inputs.shape[1], [5, 2], 1]:*\n",
    "\n",
    "* `train_inputs.shape[1]`: El número de características en los datos de entrada.\n",
    "* `[5, 2]`: La capa oculta tiene 5 neuronas de adición y 2 neuronas de multiplicación (esto corresponde a un MultKAN).\n",
    "* Multiplicación en MultKAN: La multiplicación explícita en las capas permite que el modelo capture interacciones no lineales entre las características, lo que mejora su capacidad para aprender patrones más complejos en los datos.\n",
    "* 1: Una salida del modelo.\n",
    "* `grid=3, k=3`: Configuración de la complejidad y el número de intervalos dentro de la red.\n",
    "\n",
    "El uso de multiplicación en las capas ocultas mejora la capacidad del modelo para modelar relaciones no lineales y complejas entre las entradas y las superclases, a diferencia de las redes tradicionales que solo utilizan sumas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace3cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint directory created: ./model\n",
      "saving model version 0.0\n"
     ]
    }
   ],
   "source": [
    "# Inicializo el modelo KAN\n",
    "model = KAN(width=[train_inputs.shape[1], [5,2], 1], grid=3, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da44ddaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Definir una métrica de precisión para entrenamiento y prueba\n",
    "def train_acc():\n",
    "    return torch.mean((torch.round(model(train_inputs)) == train_outputs).float()) # Aproximación de la precisión\n",
    "# round redondea a 0 o 1\n",
    "\n",
    "\n",
    "def test_acc():\n",
    "    return torch.mean((torch.round(model(test_inputs)) == test_outputs).float())\n",
    "\n",
    "Luego probar con argmax en vez de torch\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a60fdfb",
   "metadata": {},
   "source": [
    "### Definición de Métricas Personalizadas (Precisión de Entrenamiento y Prueba)\n",
    "\n",
    "En esta celda, se definen las funciones de precisión personalizadas para evaluar el desempeño del modelo durante el entrenamiento y la prueba. Se utiliza `torch.argmax()` en lugar de `round()` para obtener la clase predicha, lo que mejora la precisión.\n",
    "\n",
    "- **`torch.argmax()`**: Esta función devuelve el índice del valor máximo en un tensor a lo largo de un eje. En el caso de la clasificación, esto corresponde a la clase predicha, ya que el valor máximo de las salidas del modelo representa la clase más probable.\n",
    "  - **¿Por qué `argmax` es mejor que `round()`?**\n",
    "    - `round()` es más adecuado para predicciones continuas (como regresión), mientras que `argmax()` es específico para clasificación, ya que selecciona la clase con la mayor probabilidad.\n",
    "  \n",
    "- **Función `train_acc()` y `test_acc()`**:\n",
    "  - Calculan la precisión comparando las clases predichas con las clases reales.\n",
    "  - **Cálculo:** Compara la salida de `argmax()` con la etiqueta real (`train_outputs` o `test_outputs`) y calcula el porcentaje de coincidencias.\n",
    "\n",
    "Este enfoque garantiza una evaluación adecuada para problemas de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97e77afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las funciones de métrica personalizadas\n",
    "# argmax nos da el indice del valor maximo de la fila, lo que nos da la clase\n",
    "def train_acc():\n",
    "    predictions = model(train_inputs)\n",
    "    return torch.mean((torch.argmax(predictions, dim=1) == train_outputs).float()) \n",
    "\n",
    "def test_acc():\n",
    "    predictions = model(test_inputs)\n",
    "    return torch.mean((torch.argmax(predictions, dim=1) == test_outputs).float())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbefa1be",
   "metadata": {},
   "source": [
    "### Ajuste de la Forma de las Etiquetas\n",
    "\n",
    "La función `train_outputs.view(-1, 1)` asegura que las etiquetas de entrenamiento tengan la forma correcta, convirtiéndolas en un tensor de una sola columna (forma `(N, 1)`), donde `N` es el número de ejemplos. Esto es necesario para que las etiquetas sean compatibles con las salidas del modelo y la función de pérdida, especialmente en problemas de clasificación donde cada etiqueta debe estar en una dimensión específica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19bd895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_outputs = train_outputs.view(-1, 1) # Asegurarse de que las etiquetas tengan la forma correcta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f4cd8d",
   "metadata": {},
   "source": [
    "### Entrenamiento del Modelo y Evaluación de Precisión\n",
    "\n",
    "1. **Entrenamiento del Modelo**:\n",
    "   - `model.fit(dataset_kan, opt=\"LBFGS\", steps=50, metrics=(train_acc, test_acc))`: El optimizador **LBFGS** (Limited-memory Broyden-Fletcher-Goldfarb-Shanno) es un método de optimización que busca minimizar la función de pérdida ajustando los parámetros del modelo. Es especialmente útil en modelos que involucran funciones complejas, como KANs, y es eficiente en problemas de optimización no lineales y de alta dimensionalidad.\n",
    "   - **Uso de LBFGS**: Es adecuado cuando se busca precisión en modelos donde los gradientes y la optimización son complicados, como redes neuronales profundas.\n",
    "\n",
    "2. **Impresión de la Precisión**:\n",
    "   - `results['train_acc'][-1], results['test_acc'][-1]`: Muestra la precisión final del modelo tanto en el conjunto de entrenamiento como en el de prueba.\n",
    "\n",
    "El optimizador **LBFGS** ayuda a mejorar la convergencia del modelo en escenarios complejos y reduce el riesgo de estancamiento en óptimos locales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ac9c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "description:   0%|                                                           | 0/50 [00:00<?, ?it/s]/home/jesus_gh/miniconda3/envs/KAN_rxnfp/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "| train_loss: 3.27e+00 | test_loss: 3.30e+00 | reg: 1.78e+02 | : 100%|█| 50/50 [29:47<00:00, 35.75s/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2857142984867096, 0.3333333432674408)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.fit(dataset_kan, opt=\"LBFGS\",steps=50, metrics=(train_acc, test_acc)) # Entrenar el modelo\n",
    "results['train_acc'][-1], results['test_acc'][-1] # Imprimir la precisión del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe4c812",
   "metadata": {},
   "source": [
    "### Impresión de la Precisión Final\n",
    "\n",
    "En esta celda, se imprime la precisión final del modelo tanto para el conjunto de entrenamiento como para el conjunto de prueba:\n",
    "\n",
    "- **`results['train_acc'][-1]`**: Muestra la precisión obtenida en el conjunto de entrenamiento al final del proceso de entrenamiento.\n",
    "- **`results['test_acc'][-1]`**: Muestra la precisión obtenida en el conjunto de prueba, lo que ayuda a evaluar la capacidad de generalización del modelo.\n",
    "\n",
    "Esto proporciona una medida clave para evaluar el rendimiento del modelo después del entrenamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87d3f1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final train accuracy: 0.2857142984867096\n",
      "Final test accuracy: 0.3333333432674408\n"
     ]
    }
   ],
   "source": [
    "print(f\"Final train accuracy: {results['train_acc'][-1]}\")\n",
    "print(f\"Final test accuracy: {results['test_acc'][-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9ad880",
   "metadata": {},
   "source": [
    "### Generación de la Gráfica del Modelo\n",
    "\n",
    "El comando `model.plot()` se utiliza para generar una visualización gráfica del modelo KAN entrenado. Esto permite ver cómo el modelo ha aprendido y cómo están distribuidas las funciones de activación a lo largo de las capas. \n",
    "\n",
    "**Nota:** La generación de la gráfica puede ser computacionalmente costosa, especialmente con grandes modelos o datasets, por lo que puede causar problemas de rendimiento o incluso hacer que el kernel se detenga. A pesar de ello, este paso es útil para interpretar y visualizar el comportamiento del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645783d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07efa9d",
   "metadata": {},
   "source": [
    "### Activación Simbólica Automática\n",
    "\n",
    "Se utiliza `model.auto_symbolic(lib=lib)` para activar las funciones simbólicas en el modelo KAN. Esto convierte las funciones de activación en representaciones más comprensibles y matemáticamente interpretables, utilizando una librería de funciones predefinidas (`lib`).\n",
    "\n",
    "- **`lib`**: Lista de funciones simbólicas (como `x`, `x^2`, `exp`, etc.) que el modelo utilizará para expresar sus activaciones.\n",
    "- **¿Por qué es útil?**: Esto permite obtener una comprensión más profunda de cómo el modelo genera sus predicciones y qué funciones matemáticas está aprendiendo.\n",
    "\n",
    "Este paso facilita la interpretación del modelo y su comportamiento en términos de funciones conocidas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fc349e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lib = ['x','x^2']\n",
    "\n",
    "model.auto_symbolic(lib=lib)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1230913",
   "metadata": {},
   "source": [
    "### Obtención de la Fórmula Simbólica del Modelo\n",
    "\n",
    "En esta celda, se extrae la fórmula simbólica del modelo entrenado utilizando el método `model.symbolic_formula()`. Este método devuelve las representaciones simbólicas de las funciones que el modelo ha aprendido.\n",
    "\n",
    "- **`model.symbolic_formula()[0]`**: Extrae la primera fórmula simbólica generada por el modelo.\n",
    "- **`ex_round(formula1, 4)`**: La función `ex_round` se utiliza para redondear la fórmula a 4 decimales, facilitando su interpretación y presentación.\n",
    "\n",
    "Estas fórmulas proporcionan una forma matemática de comprender cómo el modelo toma decisiones y puede ser útil para visualizar los patrones aprendidos por el KAN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98906d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kan.utils import ex_round\n",
    "\n",
    "ex_round(model.symbolic_formula()[0][0],4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5948e231",
   "metadata": {},
   "source": [
    "### Poda del Modelo\n",
    "\n",
    "El comando `model = model.prune()` se utiliza para **podar** el modelo, es decir, eliminar las conexiones o parámetros innecesarios dentro de la red para simplificar el modelo sin perder capacidad de aprendizaje. \n",
    "\n",
    "**¿Por qué usar poda?**\n",
    "- La poda ayuda a mejorar la eficiencia del modelo, reduciendo la complejidad computacional y acelerando la inferencia sin sacrificar significativamente el rendimiento.\n",
    "\n",
    "Este paso es útil para optimizar el modelo una vez que ha sido entrenado y ajustado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae677d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model version 0.2\n"
     ]
    }
   ],
   "source": [
    "model = model.prune()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab2822",
   "metadata": {},
   "source": [
    "### Visualización del Modelo Podado\n",
    "\n",
    "El comando `model.plot()` se utiliza para visualizar el modelo **pruneado**, lo que muestra la estructura del modelo después de haber eliminado los parámetros innecesarios. Esta visualización ayuda a ver cómo el modelo ha sido simplificado y optimizado, permitiendo una interpretación más clara de la red y sus conexiones.\n",
    "\n",
    "**Nota**: La visualización puede ser computacionalmente costosa, especialmente con modelos grandes, y podría requerir recursos adicionales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f22a638a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KAN_rxnfp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
